{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the previous 3 case studies,  your team has now equipped with all the three powerful skills of data science: Hacking skill, Business skill and Math skill. In this project, your team is going to make use of these skills to come up with an idea of a new business/startup based upon data science technology. Your goal is to design a better service/solution on any data you like, develop a prototype/demo and prepare a pitch for your idea.\n",
    "* Your team needs to decide which business problem is important for the market you are joining in (for example, social media market, housing market, search market, etc.).\n",
    "* Then design a data science approach to improve one of the current services or design a new service on any data that you choose (hopefully not Yelp dataset again).\n",
    "* The solution should include all the three components of data science: 1) the business part to analyze the potential impact of your new/improved service, why the idea can make money, how much are you evaluating the company; How are you planing to persuade the sharks to invest in your business; 2) the mathematical part to formulate the problem and develop math solution; 3) the programming part to collect the data, implement the math solution, and develop the prototype/demo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background about Elevator Pitch (90 seconds) and Shark Tank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"mrSmaCo29U4\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YouTubeVideo(\"g31M8WmKeqg\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Optional Readings:** \n",
    "* LinkedIn API: https://developer.linkedin.com/docs/rest-api\n",
    "* Zillow API: https://pypi.python.org/pypi/pyzillow\n",
    "* Google Map API: https://developers.google.com/api-client-library/python/apis/mapsengine/v1?hl=en\n",
    "* More APIs: https://github.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition\n",
    "\n",
    "\n",
    "** Python libraries you may want to use:**\n",
    "* Scikit-learn (http://scikit-learn.org): machine learning tools in Python.\n",
    "\n",
    "** NOTE **\n",
    "* Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost.\n",
    "\n",
    "*----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Problem 1: the Business Part (20 points)\n",
    " As a group, learn about the data science related business and research about the current markets: such as search, social media, advertisement, recommendation and so on.\n",
    "Pick one of the markets for further consideration, and design a new service  which you believe to be important in the market. \n",
    "Define precisely in the report and briefly in the cells below, what is the business problem that your team wants to solve.\n",
    "Why the problem is important to solve? \n",
    "Why you believe you could make a big difference with data science technology.\n",
    "How are you planing to persuade the investors to buy in your idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please describe here *briefly*  (please edit this cell)**\n",
    "\n",
    "1) Your business problem to solve:\n",
    "\n",
    "\n",
    "\n",
    "2) Why the problem is important to solve? \n",
    "\n",
    "\n",
    "3) What is your idea to solve the problem? \n",
    "\n",
    "\n",
    "4) What differences you could make with your data science approach?\n",
    "\n",
    "\n",
    "5) Why do you believe the idea deserves the investment of the \"sharks\"?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Problem 2: The Math Part (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the business problem as a math problem and design a math solution to the problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insert your answers here**\n",
    "\n",
    "\n",
    "1) Problem formulation in Math:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2) Math Solution:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3) Implementation of the Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#Problem 3: The Hacking Part  (20 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data Collection\n",
    "* Implement a small Demo/Prototype/experiment result figures for the \"product\" of your data science company. You could use this demo during the Pitch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Collection**:\n",
    "This part is about pre-processing. Such like some parameter settings, street information gathering and save the data into \"data\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACADEMY',\n",
       " 'ALGONQUIN',\n",
       " 'ARDMORE',\n",
       " 'ARGYLE',\n",
       " 'ASHLAND',\n",
       " 'AUSTIN',\n",
       " 'AVALON',\n",
       " 'AYLESBURY',\n",
       " 'BANCROFT TOWER',\n",
       " 'BARROWS',\n",
       " 'BARRY',\n",
       " 'BEECHMONT',\n",
       " 'BEL AIR',\n",
       " 'BELLEVUE',\n",
       " 'BERKSHIRE',\n",
       " 'BIRCHWOOD',\n",
       " 'BLACKTHORN',\n",
       " 'BLACKWELL',\n",
       " 'BLOSSOM',\n",
       " 'BOWDOIN',\n",
       " 'BOYNTON',\n",
       " 'BREWER',\n",
       " 'BRIGHAM',\n",
       " 'BROMPTON',\n",
       " 'BROOK HILL',\n",
       " 'BROOKSHIRE',\n",
       " 'BROWNING',\n",
       " 'BURGESS',\n",
       " 'BUTTERNUT HILL',\n",
       " 'CARTER',\n",
       " 'CEDAR',\n",
       " 'CHANDLER',\n",
       " 'CHATHAM',\n",
       " 'CHESTNUT',\n",
       " 'CHESTNUT HILL',\n",
       " 'CHILTERN HILL',\n",
       " 'CLINTON',\n",
       " 'COLUMBINE',\n",
       " 'CONGRESS',\n",
       " 'COTTAGE',\n",
       " 'CROWN',\n",
       " 'DARA',\n",
       " 'DARENESS',\n",
       " 'DAYTON',\n",
       " 'DEAN',\n",
       " 'DENNISON',\n",
       " 'DENNY',\n",
       " 'DEWEY',\n",
       " 'DICK',\n",
       " 'DIX',\n",
       " 'DONNA',\n",
       " 'DOVER',\n",
       " 'DRURY',\n",
       " 'DUBIEL',\n",
       " 'EDEN',\n",
       " 'EINHORN',\n",
       " 'ELBRIDGE',\n",
       " 'ELLIS',\n",
       " 'ELM',\n",
       " 'ESSEX',\n",
       " 'FARNUM',\n",
       " 'FENIMORE',\n",
       " 'FLAGG',\n",
       " 'FLOWER HILL',\n",
       " 'FOREST',\n",
       " 'FOREST HILL',\n",
       " 'FRUIT',\n",
       " 'GEORGE',\n",
       " 'GLENBROOK',\n",
       " 'GOULDING',\n",
       " 'GREEN VIEW',\n",
       " 'GREENSIDE',\n",
       " 'GREENWICH',\n",
       " 'GROSS',\n",
       " 'HACKFELD',\n",
       " 'HAMPDEN',\n",
       " 'HANCOCK HILL',\n",
       " 'HARVARD',\n",
       " 'HAWLEY',\n",
       " 'HAZELWOOD',\n",
       " 'HICKORY',\n",
       " 'HIDDEN FARM',\n",
       " 'HIGH',\n",
       " 'HIGH ROCK',\n",
       " 'HIGHLAND',\n",
       " 'HILL',\n",
       " 'HILLTOP',\n",
       " 'HOME',\n",
       " 'HOWATSON',\n",
       " 'HOWE',\n",
       " 'HUDSON',\n",
       " 'HUMBOLDT',\n",
       " 'INSTITUTE',\n",
       " 'IRVING',\n",
       " 'JAMESBURY',\n",
       " 'JOHN',\n",
       " 'JOHN STREET',\n",
       " 'JOHN WING',\n",
       " 'KANES',\n",
       " 'KITTERING',\n",
       " 'KNIGHTSBRIDGE CLOSE',\n",
       " 'KNOLLWOOD',\n",
       " 'LACONIA',\n",
       " 'LANCASTER',\n",
       " 'LANTERN',\n",
       " 'LARCH',\n",
       " 'LEDGEWOOD',\n",
       " 'LEYTON',\n",
       " 'LINDEN',\n",
       " 'LYNNWOOD',\n",
       " 'MARSTON',\n",
       " 'MARY JANE',\n",
       " 'MASON',\n",
       " 'MASSACHUSETTS',\n",
       " 'MEADOWBROOK',\n",
       " 'MERRICK',\n",
       " 'METCALF',\n",
       " 'MILITARY',\n",
       " 'MONADNOCK',\n",
       " 'MONMOUTH',\n",
       " 'MONTCLAIR',\n",
       " 'MONTVALE',\n",
       " 'MORELAND',\n",
       " 'MORELAND GREEN',\n",
       " 'MURRAY',\n",
       " 'NEWBURY',\n",
       " 'NEWINGTON',\n",
       " 'NEWTON',\n",
       " 'NOTTINGHAM',\n",
       " 'OAK',\n",
       " 'OAK HILL',\n",
       " 'OLD BROOK',\n",
       " 'OLD COLONY',\n",
       " 'OLD ENGLISH',\n",
       " 'ORMOND',\n",
       " 'ORRISON',\n",
       " 'OTSEGO',\n",
       " 'OXFORD',\n",
       " 'PARK',\n",
       " 'PAUL REVERE',\n",
       " 'PELHAM',\n",
       " 'PEMBROOK',\n",
       " 'PIEDMONT',\n",
       " 'PINE',\n",
       " 'PINE TREE',\n",
       " 'PINEBROOK',\n",
       " 'PINEWOOD',\n",
       " 'PLEASANT',\n",
       " 'PRATT',\n",
       " 'PRIMMETT',\n",
       " 'QUEEN',\n",
       " 'QUINCY',\n",
       " 'REGENT',\n",
       " 'RIEDL',\n",
       " 'ROLLINGWOOD',\n",
       " 'ROSELAND',\n",
       " 'ROXBURY',\n",
       " 'RUSSELL',\n",
       " 'RUSTIC',\n",
       " 'RUTLAND',\n",
       " 'SAGAMORE',\n",
       " 'SALISBURY',\n",
       " 'SALISBURY CRAG',\n",
       " 'SALISBURY HILL',\n",
       " 'SANTUIT',\n",
       " 'SCHUSSLER',\n",
       " 'SEVER',\n",
       " 'SHAWMUT',\n",
       " 'SHEFFIELD',\n",
       " 'SILVER SPRUCE',\n",
       " 'SOMERSET',\n",
       " 'SOUTHWOOD',\n",
       " 'SPRING VALLEY',\n",
       " 'STAMFORD',\n",
       " 'STATE',\n",
       " 'STONEHOUSE',\n",
       " 'SUDBURY',\n",
       " 'SUMMERLAND',\n",
       " 'SUN VALLEY',\n",
       " 'SURREY',\n",
       " 'TERRACE',\n",
       " 'TIDESWELL',\n",
       " 'TOWNSEND',\n",
       " 'TROWBRIDGE',\n",
       " 'TUCKERMAN',\n",
       " 'VALLEY HILL',\n",
       " 'WACHUSETT',\n",
       " 'WACONAH',\n",
       " 'WALTER',\n",
       " 'WARING',\n",
       " 'WENDELL',\n",
       " 'WESBY',\n",
       " 'WEST',\n",
       " 'WESTWOOD',\n",
       " 'WHEELER',\n",
       " 'WHISPER',\n",
       " 'WHITEHAVEN',\n",
       " 'WHITMAN',\n",
       " 'WILLIAM',\n",
       " 'WILLOWBROOK',\n",
       " 'WILTSHIRE',\n",
       " 'WINSLOW',\n",
       " 'WOODHAVEN']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#===========================all imports, class and function defination!=======================\n",
    "from pyzillow.pyzillow import ZillowResults,ZillowWrapper, GetDeepSearchResults\n",
    "import json,pickle,os\n",
    "\n",
    "def dumps(data):\n",
    "    with open(\"data\",'wb') as out:\n",
    "        pickle.dump(data, out, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load():\n",
    "    if not os.path.exists(\"data\"):\n",
    "        dumps([None,None]) \n",
    "    with open(\"data\",\"rb\") as files:\n",
    "        data=pickle.load(files)\n",
    "        return data\n",
    "        \n",
    "def dictUpdate(old,new):\n",
    "    if len(new.keys())==0: return\n",
    "    key=new.keys()[0]\n",
    "    if old.has_key(key):\n",
    "        if old[key].__class__!=[].__class__:\n",
    "            old[key]=[old[key]]\n",
    "        old[key].append(new[key])\n",
    "    else:\n",
    "        old.update(new)\n",
    "\n",
    "def JRes(elem):\n",
    "        d=dict()\n",
    "        tag=elem.tag.split(\"}\")[-1]\n",
    "        if elem.text:\n",
    "            d[tag]=elem.text\n",
    "        children=elem.getchildren()\n",
    "        if children:\n",
    "            li=map(JRes, children)\n",
    "            content_dict={tag:[]}\n",
    "            newli={}\n",
    "            for i in li:\n",
    "                if len(i)==1 and i.has_key(tag):\n",
    "                    content_dict[tag].append(i[tag])\n",
    "                else:\n",
    "                    dictUpdate(newli,i)\n",
    "            if not content_dict[tag]:\n",
    "                content_dict={}\n",
    "            if(len(newli)>0):\n",
    "                newli.update(content_dict)\n",
    "            else:\n",
    "                newli=content_dict\n",
    "            d[tag]=newli\n",
    "        return d\n",
    "\n",
    "\n",
    "API_KEY = \"X1-ZWz19zavpa7evf_4pyss\"#\"X1-ZWz19z1o83a70r_1acr8\" Changing it! \"X1-ZWz19zavpa7evf_4pyss\" is mine\n",
    "         \n",
    "zillow_data = ZillowWrapper(API_KEY) \n",
    "\n",
    "\n",
    "\n",
    "#======================================fetch all region in MA======================================\n",
    "\n",
    "#========set_parameter_here======\n",
    "#Select an api from list on http://www.zillow.com/howto/api/APIOverview.htm \n",
    "api_url=\"http://www.zillow.com/webservice/GetRegionChildren.htm\"\n",
    "#specify parameters listed in table\n",
    "params={\n",
    "    \"zws-id\":API_KEY,   \n",
    "    \"state\":\"MA\"}\n",
    "regList=['Worcester']\n",
    "\n",
    "data=load()\n",
    "if data[0]==None:\n",
    "    #=========fetching===============\n",
    "    #Get result in MA\n",
    "    res_lv0=JRes(zillow_data.get_data(api_url,params))\n",
    "    #Get county region id list\n",
    "    res_lv1=res_lv0[\"regionchildren\"][\"response\"][\"list\"][\"region\"]\n",
    "    res_lv1_filtered=[i['id'] for i in res_lv1 if i['name'] in regList]\n",
    "    #Get to next level\n",
    "    master={}\n",
    "    for id in res_lv1_filtered:\n",
    "        res_lv2=JRes(zillow_data.get_data(api_url,{\"zws-id\":API_KEY,\"regionId\":id}))['regionchildren']['response']\n",
    "        master[res_lv2[\"region\"][\"county\"]]=res_lv2[\"list\"][\"region\"]\n",
    "    #level 3 takes a little longer\n",
    "    res_lv3=[\n",
    "        JRes(zillow_data.get_data(api_url,{\"zws-id\":API_KEY,\"regionId\":id}))['regionchildren']['response'][\"list\"]\n",
    "        for id in [j['id'] for i in regList for j in master[i]]]\n",
    "    #zip codes\n",
    "    tmp=[]\n",
    "    for i in [i['region'] for i in res_lv3 if i.has_key('region')]:\n",
    "        if i.__class__=={}.__class__:\n",
    "            tmp.append(i)\n",
    "        else:\n",
    "            tmp+=i\n",
    "    zips=[i['name'] for i in tmp]\n",
    "    data[0]=zips\n",
    "else: pass\n",
    "dumps(data)\n",
    "\n",
    "\n",
    "# ==================================Get residual addresses -_-!==============================\n",
    "# ===it is from www.melissadata.com\n",
    "import urllib2,re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def getStreet(zipcode):\n",
    "    query = zipcode\n",
    "    url = 'http://www.melissadata.com/lookups/zipstreet.asp?InData=' + query\n",
    "    req = urllib2.Request(url)\n",
    "    con = urllib2.urlopen( req)\n",
    "    doc = con.read()\n",
    "    con.close()\n",
    "    matchObj = re.finditer( r'(?<=zipstreet\\.asp\\?Step5=\\d{5,5}\\&Name=)\\w+(\\+\\w+)*', doc)\n",
    "    streets=[]\n",
    "    for m in matchObj:\n",
    "        streets.append(m.group())\n",
    "    return streets,doc \n",
    "        \n",
    "data=load()\n",
    "if data[1]==None:\n",
    "    streets={}   \n",
    "    for zipcode in data[0]:\n",
    "        print zipcode\n",
    "        street,doc=getStreet(zipcode)\n",
    "        streets[zipcode]=street\n",
    "    for i in streets:\n",
    "        #print i,streets[i]\n",
    "        for j in range(len(streets[i])):\n",
    "            streets[i][j]=streets[i][j].replace(\"+\",\" \")\n",
    "    data[1]=streets\n",
    "    \n",
    "dumps(data)\n",
    "data[1]['01609']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More collecting!**\n",
    "This part is for collecting data from zillow. Since there is a limited times of accessing zillow API, which is 1000 times per day. So we create this cell to allow us to fetch data with multiple computers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACADEMY 01609\n",
      "ALGONQUIN 01609\n",
      "ARDMORE 01609\n",
      "ARGYLE 01609\n",
      "ASHLAND 01609\n",
      "AUSTIN 01609\n",
      "AVALON 01609\n",
      "AYLESBURY 01609\n",
      "BANCROFT TOWER 01609\n",
      "BARROWS 01609\n",
      "BARRY 01609\n",
      "BEECHMONT 01609\n",
      "BEL AIR 01609\n",
      "BELLEVUE 01609\n",
      "BERKSHIRE 01609\n",
      "BIRCHWOOD 01609\n",
      "BLACKTHORN 01609\n",
      "BLACKWELL 01609\n",
      "BLOSSOM 01609\n",
      "BOWDOIN 01609\n",
      "BOYNTON 01609\n",
      "BREWER 01609\n",
      "BRIGHAM 01609\n",
      "BROMPTON 01609\n",
      "BROOK HILL 01609\n",
      "BROOKSHIRE 01609\n",
      "BROWNING 01609\n",
      "BURGESS 01609\n",
      "BUTTERNUT HILL 01609\n",
      "CARTER 01609\n",
      "CEDAR 01609\n",
      "CHANDLER 01609\n",
      "CHATHAM 01609\n",
      "CHESTNUT 01609\n",
      "CHESTNUT HILL 01609\n",
      "CHILTERN HILL 01609\n",
      "CLINTON 01609\n",
      "COLUMBINE 01609\n",
      "CONGRESS 01609\n",
      "COTTAGE 01609\n",
      "CROWN 01609\n",
      "DARA 01609\n",
      "DARENESS 01609\n",
      "DAYTON 01609\n",
      "DEAN 01609\n",
      "DENNISON 01609\n",
      "DENNY 01609\n",
      "DEWEY 01609\n",
      "DICK 01609\n",
      "DIX 01609\n",
      "DONNA 01609\n",
      "DOVER 01609\n",
      "DRURY 01609\n",
      "DUBIEL 01609\n",
      "EDEN 01609\n",
      "EINHORN 01609\n",
      "ELBRIDGE 01609\n",
      "ELLIS 01609\n",
      "ELM 01609\n",
      "ESSEX 01609\n",
      "FARNUM 01609\n",
      "FENIMORE 01609\n",
      "FLAGG 01609\n",
      "FLOWER HILL 01609\n",
      "FOREST 01609\n",
      "FOREST HILL 01609\n",
      "FRUIT 01609\n",
      "GEORGE 01609\n",
      "GLENBROOK 01609\n",
      "GOULDING 01609\n",
      "GREEN VIEW 01609\n",
      "GREENSIDE 01609\n",
      "GREENWICH 01609\n",
      "GROSS 01609\n",
      "HACKFELD 01609\n",
      "HAMPDEN 01609\n",
      "HANCOCK HILL 01609\n",
      "HARVARD 01609\n",
      "HAWLEY 01609\n",
      "HAZELWOOD 01609\n",
      "HICKORY 01609\n",
      "HIDDEN FARM 01609\n",
      "HIGH 01609\n",
      "HIGH ROCK 01609\n",
      "HIGHLAND 01609\n",
      "HILL 01609\n",
      "HILLTOP 01609\n",
      "HOME 01609\n",
      "HOWATSON 01609\n",
      "HOWE 01609\n",
      "HUDSON 01609\n",
      "HUMBOLDT 01609\n",
      "INSTITUTE 01609\n",
      "IRVING 01609\n",
      "JAMESBURY 01609\n",
      "JOHN 01609\n",
      "JOHN STREET 01609\n",
      "JOHN WING 01609\n",
      "KANES 01609\n",
      "KITTERING 01609\n",
      "KNIGHTSBRIDGE CLOSE 01609\n",
      "KNOLLWOOD 01609\n",
      "LACONIA 01609\n",
      "LANCASTER 01609\n",
      "LANTERN 01609\n",
      "LARCH 01609\n",
      "LEDGEWOOD 01609\n",
      "LEYTON 01609\n",
      "LINDEN 01609\n",
      "LYNNWOOD 01609\n",
      "MARSTON 01609\n",
      "MARY JANE 01609\n",
      "MASON 01609\n",
      "MASSACHUSETTS 01609\n",
      "MEADOWBROOK 01609\n",
      "MERRICK 01609\n",
      "METCALF 01609\n",
      "MILITARY 01609\n",
      "MONADNOCK 01609\n",
      "MONMOUTH 01609\n",
      "MONTCLAIR 01609\n",
      "MONTVALE 01609\n",
      "MORELAND 01609\n",
      "MORELAND GREEN 01609\n",
      "MURRAY 01609\n",
      "NEWBURY 01609\n",
      "NEWINGTON 01609\n",
      "NEWTON 01609\n",
      "NOTTINGHAM 01609\n",
      "OAK 01609\n",
      "OAK HILL 01609\n",
      "OLD BROOK 01609\n",
      "OLD COLONY 01609\n",
      "OLD ENGLISH 01609\n",
      "ORMOND 01609\n",
      "ORRISON 01609\n",
      "OTSEGO 01609\n",
      "OXFORD 01609\n",
      "PARK 01609\n",
      "PAUL REVERE 01609\n",
      "PELHAM 01609\n",
      "PEMBROOK 01609\n",
      "PIEDMONT 01609\n",
      "PINE 01609\n",
      "PINE TREE 01609\n",
      "PINEBROOK 01609\n",
      "PINEWOOD 01609\n",
      "PLEASANT 01609\n",
      "PRATT 01609\n",
      "PRIMMETT 01609\n",
      "QUEEN 01609\n",
      "QUINCY 01609\n",
      "REGENT 01609\n",
      "RIEDL 01609\n",
      "ROLLINGWOOD 01609\n",
      "ROSELAND 01609\n",
      "ROXBURY 01609\n",
      "RUSSELL 01609\n",
      "RUSTIC 01609\n",
      "RUTLAND 01609\n",
      "SAGAMORE 01609\n",
      "SALISBURY 01609\n",
      "SALISBURY CRAG 01609\n",
      "SALISBURY HILL 01609\n",
      "SANTUIT 01609\n",
      "SCHUSSLER 01609\n",
      "SEVER 01609\n",
      "SHAWMUT 01609\n",
      "SHEFFIELD 01609\n",
      "SILVER SPRUCE 01609\n",
      "SOMERSET 01609\n",
      "SOUTHWOOD 01609\n",
      "SPRING VALLEY 01609\n",
      "STAMFORD 01609\n",
      "STATE 01609\n",
      "STONEHOUSE 01609\n",
      "SUDBURY 01609\n",
      "SUMMERLAND 01609\n",
      "SUN VALLEY 01609\n",
      "SURREY 01609\n",
      "TERRACE 01609\n",
      "TIDESWELL 01609\n",
      "TOWNSEND 01609\n",
      "TROWBRIDGE 01609\n",
      "TUCKERMAN 01609\n",
      "VALLEY HILL 01609\n",
      "WACHUSETT 01609\n",
      "WACONAH 01609\n",
      "WALTER 01609\n",
      "WARING 01609\n",
      "WENDELL 01609\n",
      "WESBY 01609\n",
      "WEST 01609\n",
      "WESTWOOD 01609\n",
      "WHEELER 01609\n",
      "WHISPER 01609\n",
      "WHITEHAVEN 01609\n",
      "WHITMAN 01609\n",
      "WILLIAM 01609\n",
      "WILLOWBROOK 01609\n",
      "WILTSHIRE 01609\n",
      "WINSLOW 01609\n",
      "WOODHAVEN 01609\n"
     ]
    }
   ],
   "source": [
    "#get property details\n",
    "\n",
    "def getZpid(addr,zipcode):\n",
    "    #========set_parameter_here======\n",
    "    api_url=\"http://www.zillow.com/webservice/GetDeepSearchResults.htm\"\n",
    "    #specify parameters listed in table\n",
    "    params={\"zws-id\":API_KEY,\"address\":addr,\"citystatezip\":zipcode}\n",
    "\n",
    "    #=========fetching===============\n",
    "    #Get result in MA\n",
    "    \n",
    "    return JRes(zillow_data.get_data(api_url,params))[\"searchresults\"]['response']#['results']['result']\n",
    "zipPool=[\"01609\",]\n",
    "streetPool=data[1]['01609']#################### ADD ST NAME HERE listed on above cell #####################\n",
    "data=load()\n",
    "if len(data)==2:\n",
    "    zpidList={}\n",
    "    data.append(None)\n",
    "elif len(data)==3:\n",
    "    zpidList=data[2]    \n",
    "\n",
    "for zipcode in data[1]:\n",
    "    #print 111#######\n",
    "    if not zipcode in zipPool:\n",
    "        continue#Just retrieve zipcode in Pool\n",
    "    if not zpidList.has_key(zipcode): \n",
    "        zpidList[zipcode]={\"content\":{},\"Done\":False}\n",
    "    if zpidList[zipcode][\"Done\"]:continue\n",
    "    else:\n",
    "        for street in data[1][zipcode]:\n",
    "            #print 222#######\n",
    "            if not street in streetPool:\n",
    "                continue#Just retrieve streets in Pool\n",
    "            print street,zipcode\n",
    "            if not zpidList[zipcode][\"content\"].has_key(street):\n",
    "                zpidList[zipcode][\"content\"][street]={\"content\":{},\"Done\":False}\n",
    "            if zpidList[zipcode][\"content\"][street][\"Done\"]:\n",
    "                continue\n",
    "            else:\n",
    "                fail_times=0\n",
    "                cont_fail_times=0\n",
    "                for i in range(1,999):\n",
    "                    #print 333#######\n",
    "                    if fail_times>200 or cont_fail_times>50 and i>100 : \n",
    "                        print i,fail_times,cont_fail_times\n",
    "                        zpidList[zipcode][\"content\"][street][\"Done\"]=True\n",
    "                        break\n",
    "                    if zpidList[zipcode][\"content\"][street][\"content\"].has_key(i) and zpidList[zipcode][\"content\"][street][\"content\"][i] :continue\n",
    "                    try:\n",
    "                        zpidList[zipcode][\"content\"][street][\"content\"][i]=getZpid(str(i)+\" \"+street,zipcode)\n",
    "                        print \"success! \",str(i)+\" \"+street,zipcode\n",
    "                        cont_fail_times=0\n",
    "                        data[2]=zpidList\n",
    "                        dumps(data)\n",
    "                    except Exception as err:\n",
    "                        if err.message==7: \n",
    "                            print \"OUT OF TIMES\"\n",
    "                            break\n",
    "                        zpidList[zipcode][\"content\"][street][\"content\"][i]=None\n",
    "                        print \"Fails!   \",str(i)+\" \"+street,zipcode,err.message\n",
    "                        fail_times+=1\n",
    "                        cont_fail_times+=1\n",
    "            \n",
    "    #zpidList[zipcode][\"Done\"]=True\n",
    "data[2]=zpidList\n",
    "dumps(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Part,  Saber. Two functions help you access data I collected.   \n",
    "The problem is Zillow just provides the house value estimate. Maybe you can work on that, \"Zestimate\".   \n",
    "Other problem is, since zillow api does not allow me access it over 1000 times, so just get the housees **ONLY ON HIGHLAND ST**. If you need more I can keep working on it and try use different computers to get more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 HIGHLAND, 01609\n",
      "  | totalRooms : 21\n",
      "  | lotSizeSqFt : 5489\n",
      "  | finishedSqFt : 4755\n",
      "  | taxAssessmentYear : 2015\n",
      "  | zestimate : {'valueChange': '-4219', 'amount': '288041', 'percentile': '0', 'valuationRange': {'high': '305323', 'low': '264998'}, 'last-updated': '12/01/2015'}\n",
      "  | bathrooms : 3.0\n",
      "  | bedrooms : 9\n",
      "  | FIPScounty : 25027\n",
      "  | taxAssessment : 203400.0\n",
      "  | yearBuilt : 1905\n",
      "  | useCode : MultiFamily2To4\n",
      "  | zpid : 56735656\n",
      "\n",
      "Houses Number is 4360\n",
      "\n",
      "\n",
      "http://www.zillow.com/howto/api/GetRateSummary.htm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rateSummary': {'message': {'code': '0',\n",
       "   'text': 'Request successfully processed'},\n",
       "  'response': {'lastWeek': {'rate': ['3.8', '2.98', '3.04']},\n",
       "   'today': {'rate': ['3.86', '3.03', '3.09']}}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mortgate provided by zillow\n",
    "def getMortgate(state=None):\n",
    "    url='http://www.zillow.com/webservice/GetRateSummary.htm'\n",
    "    return JRes(zillow_data.get_data(url,{\"zws-id\":API_KEY,'state':state}))  \n",
    "\n",
    "#Just a example saber. You can mod this func anyway, data is in \"tmp\" variable. Just get want you what\n",
    "def itsYourDataSaber():\n",
    "    tmp=load()[2].copy()\n",
    "    zdata={}\n",
    "    for i in tmp:\n",
    "        for j in tmp[i][\"content\"]:\n",
    "            for k,v in tmp[i][\"content\"][j][\"content\"].iteritems():\n",
    "                if v:\n",
    "                    t=v[\"results\"][\"result\"]\n",
    "                    if t.__class__!=[].__class__: t=[t]\n",
    "                    zdata[str(k)+\" \"+j+\", \"+i]=t\n",
    "    return zdata\n",
    "#This is example that How to access data\n",
    "\n",
    "for i,v in itsYourDataSaber().iteritems():\n",
    "    for j in v:\n",
    "        if i==\"226 HIGHLAND, 01609\":\n",
    "            print i\n",
    "            for key in j.keys():\n",
    "                if key in [\"links\",'address',\"localRealEstate\"]: continue\n",
    "                print \"  |\",key,\":\",j[key]\n",
    "                \n",
    "print \"\\nHouses Number is\",len(itsYourDataSaber())               \n",
    "\n",
    "print \"\\n\\nhttp://www.zillow.com/howto/api/GetRateSummary.htm\"                \n",
    "getMortgate(\"MA\") \n",
    "#itsYourDataSaber()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*------------------------\n",
    "\n",
    "#Bonus Question: Prepare a 90 second Pitch and *present* it in the class (10 points)\n",
    "\n",
    "* Prepare the slides for the Pitch (5 points)\n",
    "* Present it in the class before your 10-minute talk (5 points).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------\n",
    "# Done\n",
    "\n",
    "All set! \n",
    "\n",
    "** What do you need to submit?**\n",
    "\n",
    "* **Notebook File** (60 points): Save this IPython notebook.\n",
    "\n",
    "\n",
    "* **PPT Slides** (20 points): please prepare PPT slides (for 10 minutes' talk) to present about the case study . \n",
    "\n",
    "* ** Report** (20 points): please prepare a report (less than 10 pages) to report what you did in this project.\n",
    "\n",
    "     (please include figures or tables in the report, but no source code)\n",
    "\n",
    "Please compress all the files in a zipped file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
